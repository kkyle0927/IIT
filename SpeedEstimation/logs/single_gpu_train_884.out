Job started on server1 at Wed Feb 18 02:56:29 PM KST 2026
CUDA_VISIBLE_DEVICES=0,1,2
GPU 0: NVIDIA RTX A5000 (UUID: GPU-f411cc27-8b1b-872b-45e8-d981ad07efac)
GPU 1: NVIDIA RTX A5000 (UUID: GPU-a792101e-894b-2a35-89fd-d11e1db52899)
GPU 2: NVIDIA RTX A5000 (UUID: GPU-0419b0c5-28d5-d3c3-b641-5b0ae0dfd5bf)
[TRAIN.SH] Running LPF Check...
[INFO] Using LPF settings from configs/baseline.yaml: Cutoff=0.5Hz, Order=4
[INFO] Analyzing subject: S004 from combined_data.h5
Saved filtered_velocity/S004_accel_sine_lpf_0.5Hz.png
Saved filtered_velocity/S004_decline_5deg_lpf_0.5Hz.png
Saved filtered_velocity/S004_incline_10deg_lpf_0.5Hz.png
Saved filtered_velocity/S004_level_075mps_lpf_0.5Hz.png
Saved filtered_velocity/S004_level_100mps_lpf_0.5Hz.png
Saved filtered_velocity/S004_level_125mps_lpf_0.5Hz.png
Saved filtered_velocity/S004_stopandgo_lpf_0.5Hz.png
[setup] Detected 3 GPUs allocated by SLURM.
[SCHEDULER] Starting queue (20 items).
[SCHEDULER] Launching Exp_IMU_Orientation.yaml on GPU 0
[SCHEDULER] Launching baseline.yaml on GPU 1
[SCHEDULER] Launching exp_ar_feedback_k1.yaml on GPU 2
[SCHEDULER] GPU 2 job finished.
[SCHEDULER] Launching exp_ar_feedback_sched.yaml on GPU 2
[SCHEDULER] GPU 1 job finished.
[SCHEDULER] Launching exp_multistep_H05.yaml on GPU 1
[SCHEDULER] GPU 0 job finished.
[SCHEDULER] Launching exp_multistep_H10.yaml on GPU 0
[SCHEDULER] GPU 2 job finished.
[SCHEDULER] Launching exp_multistep_H10_ema_a090.yaml on GPU 2
[SCHEDULER] GPU 1 job finished.
[SCHEDULER] Launching exp_multistep_H10_overlap_mean.yaml on GPU 1
[SCHEDULER] GPU 0 job finished.
[SCHEDULER] Launching exp_multistep_H10_overlap_median.yaml on GPU 0
[SCHEDULER] GPU 2 job finished.
[SCHEDULER] Launching exp_multistep_H10_overlap_wmean.yaml on GPU 2
[SCHEDULER] GPU 1 job finished.
[SCHEDULER] Launching exp_multistep_H10_smooth_lam001.yaml on GPU 1
[SCHEDULER] GPU 0 job finished.
[SCHEDULER] Launching exp_multistep_H10_smooth_lam01.yaml on GPU 0
[SCHEDULER] GPU 2 job finished.
[SCHEDULER] Launching exp_multistep_H10_smooth_lam05.yaml on GPU 2
[SCHEDULER] GPU 1 job finished.
[SCHEDULER] Launching exp_multistep_H20.yaml on GPU 1
[SCHEDULER] GPU 0 job finished.
[SCHEDULER] Launching exp_single_ema_a080.yaml on GPU 0
[SCHEDULER] GPU 1 job finished.
[SCHEDULER] Launching exp_single_ema_a090.yaml on GPU 1
[SCHEDULER] GPU 2 job finished.
[SCHEDULER] Launching exp_single_ema_a095.yaml on GPU 2
[SCHEDULER] GPU 0 job finished.
[SCHEDULER] Launching exp_tcn_gru_head_h32.yaml on GPU 0
[SCHEDULER] GPU 1 job finished.
[SCHEDULER] Launching exp_tcn_gru_head_h32_smooth.yaml on GPU 1
[SCHEDULER] GPU 2 job finished.
[SCHEDULER] Launching exp_tcn_gru_head_h64.yaml on GPU 2
[SCHEDULER] GPU 0 job finished.
[SCHEDULER] GPU 1 job finished.
[SCHEDULER] GPU 2 job finished.
[SCHEDULER] All training jobs finished. Starting comparison...
No display found. Using non-interactive Agg backend.
[INFO] Resources optimized: 1 GPU, 16 CPU Threads max.
[AUTO] Searching for all subfolders in experiments
[AUTO] Found 60 experiments to analyze.
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (70404, 1)
[EVAL] Results: MAE=0.0219, RMSE=0.0370, R²=0.9862, Lag=578.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (70201,)
[EVAL] Results: MAE=0.0124, RMSE=0.0274, R²=0.9924, Lag=738.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (70201, 1)
[EVAL] Results: MAE=0.0124, RMSE=0.0276, R²=0.9923, Lag=720.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0175, RMSE=0.0424, R²=0.9818, Lag=8981.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m1_S004_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/baseline_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0575, R²=0.9667, Lag=-11663.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (377555,)
[EVAL] Results: MAE=0.0465, RMSE=0.0786, R²=0.9536, Lag=20.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m1_S011_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0178, RMSE=0.0304, R²=0.9906, Lag=-12466.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m2_S008_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m2_S008_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0268, RMSE=0.0441, R²=0.9854, Lag=0.5ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (70404,)
[EVAL] Results: MAE=0.0220, RMSE=0.0371, R²=0.9861, Lag=588.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m1_S011_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/baseline_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0292, R²=0.9914, Lag=-1571.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0573, R²=0.9669, Lag=-11668.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0778, RMSE=0.1195, R²=0.8927, Lag=9.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0630, R²=0.9702, Lag=6.5ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m1_S011_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m1_S011_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0227, RMSE=0.0370, R²=0.9861, Lag=9406.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (70380, 5, 1)
[EVAL] Results: MAE=0.0962, RMSE=0.1381, R²=0.8077, Lag=-7043.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m1_S004_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0445, RMSE=0.0668, R²=0.9550, Lag=448.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (70201,)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9923, Lag=721.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (70177, 5, 1)
[EVAL] Results: MAE=0.0150, RMSE=0.0294, R²=0.9913, Lag=4815.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0175, RMSE=0.0424, R²=0.9818, Lag=8981.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0375, R²=0.9858, Lag=610.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0329, RMSE=0.0675, R²=0.9658, Lag=2.5ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0281, RMSE=0.0414, R²=0.9827, Lag=268.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (70087, 20, 1)
[EVAL] Results: MAE=0.0209, RMSE=0.0408, R²=0.9832, Lag=-2330.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0281, RMSE=0.0414, R²=0.9827, Lag=268.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0242, RMSE=0.0537, R²=0.9707, Lag=-468.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0291, R²=0.9914, Lag=-1573.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m2_S008_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/baseline_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0632, R²=0.9700, Lag=6.5ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (377555, 1)
[EVAL] Results: MAE=0.0464, RMSE=0.0789, R²=0.9533, Lag=20.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0329, RMSE=0.0675, R²=0.9658, Lag=2.5ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m1_S004_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m1_S004_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0332, RMSE=0.0497, R²=0.9750, Lag=12610.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (70290, 20, 1)
[EVAL] Results: MAE=0.0490, RMSE=0.0771, R²=0.9401, Lag=-6661.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0574, R²=0.9668, Lag=-11665.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (377475, 5, 1)
[EVAL] Results: MAE=0.0353, RMSE=0.0622, R²=0.9709, Lag=24.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0145, RMSE=0.0291, R²=0.9914, Lag=-1575.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0274, R²=0.9924, Lag=763.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m1_S004_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0445, RMSE=0.0668, R²=0.9550, Lag=448.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0574, R²=0.9668, Lag=-11665.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (377175, 20, 1)
[EVAL] Results: MAE=0.0524, RMSE=0.0787, R²=0.9534, Lag=41.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0631, R²=0.9701, Lag=6.5ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (377555,)
[EVAL] Results: MAE=0.0468, RMSE=0.0790, R²=0.9531, Lag=25.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0291, R²=0.9914, Lag=-1573.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0631, R²=0.9701, Lag=6.5ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m2_S008_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0261, RMSE=0.0458, R²=0.9842, Lag=4.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0802, R²=0.9517, Lag=33.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (70404,)
[EVAL] Results: MAE=0.0221, RMSE=0.0370, R²=0.9862, Lag=570.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0155, RMSE=0.0283, R²=0.9919, Lag=7448.3ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m1_S011_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0178, RMSE=0.0304, R²=0.9906, Lag=-12466.7ms
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m2_S008_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0261, RMSE=0.0458, R²=0.9842, Lag=4.0ms

[INFO] Generating detailed reports for 60 results...
[1/60] Processing: exp_multistep_H10_overlap_median_Test-m1_S004_seed42 -> exp_multistep_H10_overlap_median_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_overlap_median_Test-m1_S004_seed42/exp_multistep_H10_overlap_median_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (70404, 1)
[EVAL] Results: MAE=0.0219, RMSE=0.0370, R²=0.9862, Lag=578.3ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_median_Test-m1_S004_seed42/exp_multistep_H10_overlap_median_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_median_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_median_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[2/60] Processing: exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42 -> exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42/exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42/exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[3/60] Processing: exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42 -> exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42/exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (70201,)
[EVAL] Results: MAE=0.0124, RMSE=0.0274, R²=0.9924, Lag=738.3ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42/exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[4/60] Processing: exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42 -> exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42/exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42/exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[5/60] Processing: exp_multistep_H10_Test-m1_S011_seed42 -> exp_multistep_H10_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_Test-m1_S011_seed42/exp_multistep_H10_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_Test-m1_S011_seed42/exp_multistep_H10_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[6/60] Processing: exp_multistep_H10_overlap_median_Test-m1_S011_seed42 -> exp_multistep_H10_overlap_median_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_overlap_median_Test-m1_S011_seed42/exp_multistep_H10_overlap_median_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (70201, 1)
[EVAL] Results: MAE=0.0124, RMSE=0.0276, R²=0.9923, Lag=720.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_median_Test-m1_S011_seed42/exp_multistep_H10_overlap_median_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_median_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_median_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[7/60] Processing: exp_tcn_gru_head_h32_Test-m1_S011_seed42 -> exp_tcn_gru_head_h32_Test-m1_S011_seed42
Saved compare_result/exp_tcn_gru_head_h32_Test-m1_S011_seed42/exp_tcn_gru_head_h32_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0175, RMSE=0.0424, R²=0.9818, Lag=8981.7ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h32_Test-m1_S011_seed42/exp_tcn_gru_head_h32_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h32_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h32_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[8/60] Processing: baseline_Test-m1_S004_seed42 -> baseline_Test-m1_S004_seed42
Saved compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m1_S004_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/baseline_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0575, R²=0.9667, Lag=-11663.3ms
  [SAVED] Trajectory plot: compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for baseline_Test-m1_S004_seed42...
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/m1_S004_level_08mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/m1_S004_level_12mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/m1_S004_level_16mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/m1_S004_accel_sine.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/m1_S004_decline_5deg.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S004_seed42/baseline_Test-m1_S004_seed42/m1_S004_incline_10deg.png
  -> Calculating Feature Importance for baseline_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for baseline_Test-m1_S004_seed42: name 'h5py' is not defined
[9/60] Processing: exp_multistep_H10_overlap_mean_Test-m2_S008_seed42 -> exp_multistep_H10_overlap_mean_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_overlap_mean_Test-m2_S008_seed42/exp_multistep_H10_overlap_mean_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (377555,)
[EVAL] Results: MAE=0.0465, RMSE=0.0786, R²=0.9536, Lag=20.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_mean_Test-m2_S008_seed42/exp_multistep_H10_overlap_mean_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_mean_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_mean_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[10/60] Processing: exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42 -> exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42/exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42/exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[11/60] Processing: exp_multistep_H10_Test-m2_S008_seed42 -> exp_multistep_H10_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_Test-m2_S008_seed42/exp_multistep_H10_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_Test-m2_S008_seed42/exp_multistep_H10_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[12/60] Processing: exp_ar_feedback_sched_Test-m1_S011_seed42 -> exp_ar_feedback_sched_Test-m1_S011_seed42
Saved compare_result/exp_ar_feedback_sched_Test-m1_S011_seed42/exp_ar_feedback_sched_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m1_S011_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0178, RMSE=0.0304, R²=0.9906, Lag=-12466.7ms
  [SAVED] Trajectory plot: compare_result/exp_ar_feedback_sched_Test-m1_S011_seed42/exp_ar_feedback_sched_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_ar_feedback_sched_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_ar_feedback_sched_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 31, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[13/60] Processing: Exp_IMU_Orientation_Test-m2_S008_seed42 -> Exp_IMU_Orientation_Test-m2_S008_seed42
Saved compare_result/Exp_IMU_Orientation_Test-m2_S008_seed42/Exp_IMU_Orientation_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m2_S008_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m2_S008_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0268, RMSE=0.0441, R²=0.9854, Lag=0.5ms
  [SAVED] Trajectory plot: compare_result/Exp_IMU_Orientation_Test-m2_S008_seed42/Exp_IMU_Orientation_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for Exp_IMU_Orientation_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for Exp_IMU_Orientation_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 28, 5]) from checkpoint, the shape in current model is torch.Size([64, 28, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 28, 5]) from checkpoint, the shape in current model is torch.Size([64, 28, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 28, 1]) from checkpoint, the shape in current model is torch.Size([64, 28, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[14/60] Processing: exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42 -> exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42/exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (70404,)
[EVAL] Results: MAE=0.0220, RMSE=0.0371, R²=0.9861, Lag=588.3ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42/exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[15/60] Processing: baseline_Test-m1_S011_seed42 -> baseline_Test-m1_S011_seed42
Saved compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m1_S011_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/baseline_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0292, R²=0.9914, Lag=-1571.7ms
  [SAVED] Trajectory plot: compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for baseline_Test-m1_S011_seed42...
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/m1_S011_level_08mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/m1_S011_level_12mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/m1_S011_level_16mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/m1_S011_accel_sine.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/m1_S011_decline_5deg.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m1_S011_seed42/baseline_Test-m1_S011_seed42/m1_S011_incline_10deg.png
  -> Calculating Feature Importance for baseline_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for baseline_Test-m1_S011_seed42: name 'h5py' is not defined
[16/60] Processing: exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42 -> exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42/exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42/exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[17/60] Processing: exp_single_ema_a080_Test-m1_S004_seed42 -> exp_single_ema_a080_Test-m1_S004_seed42
Saved compare_result/exp_single_ema_a080_Test-m1_S004_seed42/exp_single_ema_a080_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0573, R²=0.9669, Lag=-11668.3ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a080_Test-m1_S004_seed42/exp_single_ema_a080_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a080_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a080_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[18/60] Processing: exp_tcn_gru_head_h64_Test-m2_S008_seed42 -> exp_tcn_gru_head_h64_Test-m2_S008_seed42
Saved compare_result/exp_tcn_gru_head_h64_Test-m2_S008_seed42/exp_tcn_gru_head_h64_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0778, RMSE=0.1195, R²=0.8927, Lag=9.0ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h64_Test-m2_S008_seed42/exp_tcn_gru_head_h64_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h64_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h64_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[19/60] Processing: exp_single_ema_a080_Test-m2_S008_seed42 -> exp_single_ema_a080_Test-m2_S008_seed42
Saved compare_result/exp_single_ema_a080_Test-m2_S008_seed42/exp_single_ema_a080_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0630, R²=0.9702, Lag=6.5ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a080_Test-m2_S008_seed42/exp_single_ema_a080_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a080_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a080_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[20/60] Processing: Exp_IMU_Orientation_Test-m1_S011_seed42 -> Exp_IMU_Orientation_Test-m1_S011_seed42
Saved compare_result/Exp_IMU_Orientation_Test-m1_S011_seed42/Exp_IMU_Orientation_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m1_S011_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m1_S011_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0227, RMSE=0.0370, R²=0.9861, Lag=9406.7ms
  [SAVED] Trajectory plot: compare_result/Exp_IMU_Orientation_Test-m1_S011_seed42/Exp_IMU_Orientation_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for Exp_IMU_Orientation_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for Exp_IMU_Orientation_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 28, 5]) from checkpoint, the shape in current model is torch.Size([64, 28, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 28, 5]) from checkpoint, the shape in current model is torch.Size([64, 28, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 28, 1]) from checkpoint, the shape in current model is torch.Size([64, 28, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[21/60] Processing: exp_multistep_H05_Test-m1_S004_seed42 -> exp_multistep_H05_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H05_Test-m1_S004_seed42/exp_multistep_H05_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (70380, 5, 1)
[EVAL] Results: MAE=0.0962, RMSE=0.1381, R²=0.8077, Lag=-7043.3ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H05_Test-m1_S004_seed42/exp_multistep_H05_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H05_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H05_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([5, 64]) from checkpoint, the shape in current model is torch.Size([5, 128]).
[22/60] Processing: exp_ar_feedback_sched_Test-m1_S004_seed42 -> exp_ar_feedback_sched_Test-m1_S004_seed42
Saved compare_result/exp_ar_feedback_sched_Test-m1_S004_seed42/exp_ar_feedback_sched_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m1_S004_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0445, RMSE=0.0668, R²=0.9550, Lag=448.3ms
  [SAVED] Trajectory plot: compare_result/exp_ar_feedback_sched_Test-m1_S004_seed42/exp_ar_feedback_sched_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_ar_feedback_sched_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_ar_feedback_sched_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 31, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[23/60] Processing: exp_multistep_H10_overlap_mean_Test-m1_S011_seed42 -> exp_multistep_H10_overlap_mean_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_overlap_mean_Test-m1_S011_seed42/exp_multistep_H10_overlap_mean_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (70201,)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9923, Lag=721.7ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_mean_Test-m1_S011_seed42/exp_multistep_H10_overlap_mean_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_mean_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_mean_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[24/60] Processing: exp_multistep_H05_Test-m1_S011_seed42 -> exp_multistep_H05_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H05_Test-m1_S011_seed42/exp_multistep_H05_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (70177, 5, 1)
[EVAL] Results: MAE=0.0150, RMSE=0.0294, R²=0.9913, Lag=4815.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H05_Test-m1_S011_seed42/exp_multistep_H05_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H05_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H05_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([5, 64]) from checkpoint, the shape in current model is torch.Size([5, 128]).
[25/60] Processing: exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42 -> exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42
Saved compare_result/exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42/exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0175, RMSE=0.0424, R²=0.9818, Lag=8981.7ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42/exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[26/60] Processing: exp_multistep_H10_ema_a090_Test-m1_S004_seed42 -> exp_multistep_H10_ema_a090_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_ema_a090_Test-m1_S004_seed42/exp_multistep_H10_ema_a090_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0375, R²=0.9858, Lag=610.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_ema_a090_Test-m1_S004_seed42/exp_multistep_H10_ema_a090_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_ema_a090_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_ema_a090_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[27/60] Processing: exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42 -> exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42
Saved compare_result/exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42/exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0329, RMSE=0.0675, R²=0.9658, Lag=2.5ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42/exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[28/60] Processing: exp_tcn_gru_head_h32_Test-m1_S004_seed42 -> exp_tcn_gru_head_h32_Test-m1_S004_seed42
Saved compare_result/exp_tcn_gru_head_h32_Test-m1_S004_seed42/exp_tcn_gru_head_h32_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0281, RMSE=0.0414, R²=0.9827, Lag=268.3ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h32_Test-m1_S004_seed42/exp_tcn_gru_head_h32_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h32_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h32_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[29/60] Processing: exp_multistep_H20_Test-m1_S011_seed42 -> exp_multistep_H20_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H20_Test-m1_S011_seed42/exp_multistep_H20_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (70087, 20, 1)
[EVAL] Results: MAE=0.0209, RMSE=0.0408, R²=0.9832, Lag=-2330.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H20_Test-m1_S011_seed42/exp_multistep_H20_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H20_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H20_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 128]).
[30/60] Processing: exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42 -> exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42
Saved compare_result/exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42/exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0281, RMSE=0.0414, R²=0.9827, Lag=268.3ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42/exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[31/60] Processing: exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42 -> exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42/exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42/exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[32/60] Processing: exp_tcn_gru_head_h64_Test-m1_S011_seed42 -> exp_tcn_gru_head_h64_Test-m1_S011_seed42
Saved compare_result/exp_tcn_gru_head_h64_Test-m1_S011_seed42/exp_tcn_gru_head_h64_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0242, RMSE=0.0537, R²=0.9707, Lag=-468.3ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h64_Test-m1_S011_seed42/exp_tcn_gru_head_h64_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h64_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h64_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[33/60] Processing: exp_single_ema_a095_Test-m1_S011_seed42 -> exp_single_ema_a095_Test-m1_S011_seed42
Saved compare_result/exp_single_ema_a095_Test-m1_S011_seed42/exp_single_ema_a095_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0291, R²=0.9914, Lag=-1573.3ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a095_Test-m1_S011_seed42/exp_single_ema_a095_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a095_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a095_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[34/60] Processing: baseline_Test-m2_S008_seed42 -> baseline_Test-m2_S008_seed42
Saved compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m2_S008_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/baseline_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0632, R²=0.9700, Lag=6.5ms
  [SAVED] Trajectory plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for baseline_Test-m2_S008_seed42...
  [SAVED] Detail Plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/m2_S008_level_075mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/m2_S008_level_100mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/m2_S008_level_125mps.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/m2_S008_accel_sine.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/m2_S008_decline_5deg.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/m2_S008_incline_10deg.png
  [SAVED] Detail Plot: compare_result/baseline_Test-m2_S008_seed42/baseline_Test-m2_S008_seed42/m2_S008_stopandgo.png
  -> Calculating Feature Importance for baseline_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for baseline_Test-m2_S008_seed42: name 'h5py' is not defined
[35/60] Processing: exp_multistep_H10_overlap_median_Test-m2_S008_seed42 -> exp_multistep_H10_overlap_median_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_overlap_median_Test-m2_S008_seed42/exp_multistep_H10_overlap_median_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (377555, 1)
[EVAL] Results: MAE=0.0464, RMSE=0.0789, R²=0.9533, Lag=20.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_median_Test-m2_S008_seed42/exp_multistep_H10_overlap_median_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_median_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_median_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[36/60] Processing: exp_tcn_gru_head_h32_Test-m2_S008_seed42 -> exp_tcn_gru_head_h32_Test-m2_S008_seed42
Saved compare_result/exp_tcn_gru_head_h32_Test-m2_S008_seed42/exp_tcn_gru_head_h32_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0329, RMSE=0.0675, R²=0.9658, Lag=2.5ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h32_Test-m2_S008_seed42/exp_tcn_gru_head_h32_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h32_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h32_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[37/60] Processing: Exp_IMU_Orientation_Test-m1_S004_seed42 -> Exp_IMU_Orientation_Test-m1_S004_seed42
Saved compare_result/Exp_IMU_Orientation_Test-m1_S004_seed42/Exp_IMU_Orientation_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m1_S004_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m1_S004_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0332, RMSE=0.0497, R²=0.9750, Lag=12610.0ms
  [SAVED] Trajectory plot: compare_result/Exp_IMU_Orientation_Test-m1_S004_seed42/Exp_IMU_Orientation_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for Exp_IMU_Orientation_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for Exp_IMU_Orientation_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 28, 5]) from checkpoint, the shape in current model is torch.Size([64, 28, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 28, 5]) from checkpoint, the shape in current model is torch.Size([64, 28, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 28, 1]) from checkpoint, the shape in current model is torch.Size([64, 28, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[38/60] Processing: exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42 -> exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42/exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42/exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[39/60] Processing: exp_multistep_H20_Test-m1_S004_seed42 -> exp_multistep_H20_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H20_Test-m1_S004_seed42/exp_multistep_H20_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (70290, 20, 1)
[EVAL] Results: MAE=0.0490, RMSE=0.0771, R²=0.9401, Lag=-6661.7ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H20_Test-m1_S004_seed42/exp_multistep_H20_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H20_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H20_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 128]).
[40/60] Processing: exp_single_ema_a090_Test-m1_S004_seed42 -> exp_single_ema_a090_Test-m1_S004_seed42
Saved compare_result/exp_single_ema_a090_Test-m1_S004_seed42/exp_single_ema_a090_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0574, R²=0.9668, Lag=-11665.0ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a090_Test-m1_S004_seed42/exp_single_ema_a090_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a090_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a090_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[41/60] Processing: exp_multistep_H05_Test-m2_S008_seed42 -> exp_multistep_H05_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H05_Test-m2_S008_seed42/exp_multistep_H05_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (377475, 5, 1)
[EVAL] Results: MAE=0.0353, RMSE=0.0622, R²=0.9709, Lag=24.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H05_Test-m2_S008_seed42/exp_multistep_H05_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H05_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H05_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([5, 64]) from checkpoint, the shape in current model is torch.Size([5, 128]).
[42/60] Processing: exp_single_ema_a080_Test-m1_S011_seed42 -> exp_single_ema_a080_Test-m1_S011_seed42
Saved compare_result/exp_single_ema_a080_Test-m1_S011_seed42/exp_single_ema_a080_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0145, RMSE=0.0291, R²=0.9914, Lag=-1575.0ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a080_Test-m1_S011_seed42/exp_single_ema_a080_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a080_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a080_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[43/60] Processing: exp_multistep_H10_ema_a090_Test-m1_S011_seed42 -> exp_multistep_H10_ema_a090_Test-m1_S011_seed42
Saved compare_result/exp_multistep_H10_ema_a090_Test-m1_S011_seed42/exp_multistep_H10_ema_a090_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0274, R²=0.9924, Lag=763.3ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_ema_a090_Test-m1_S011_seed42/exp_multistep_H10_ema_a090_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_ema_a090_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_ema_a090_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[44/60] Processing: exp_ar_feedback_k1_Test-m1_S004_seed42 -> exp_ar_feedback_k1_Test-m1_S004_seed42
Saved compare_result/exp_ar_feedback_k1_Test-m1_S004_seed42/exp_ar_feedback_k1_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m1_S004_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0445, RMSE=0.0668, R²=0.9550, Lag=448.3ms
  [SAVED] Trajectory plot: compare_result/exp_ar_feedback_k1_Test-m1_S004_seed42/exp_ar_feedback_k1_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_ar_feedback_k1_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_ar_feedback_k1_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 31, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[45/60] Processing: exp_single_ema_a095_Test-m1_S004_seed42 -> exp_single_ema_a095_Test-m1_S004_seed42
Saved compare_result/exp_single_ema_a095_Test-m1_S004_seed42/exp_single_ema_a095_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0574, R²=0.9668, Lag=-11665.0ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a095_Test-m1_S004_seed42/exp_single_ema_a095_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a095_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a095_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[46/60] Processing: exp_multistep_H20_Test-m2_S008_seed42 -> exp_multistep_H20_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H20_Test-m2_S008_seed42/exp_multistep_H20_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (377175, 20, 1)
[EVAL] Results: MAE=0.0524, RMSE=0.0787, R²=0.9534, Lag=41.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H20_Test-m2_S008_seed42/exp_multistep_H20_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H20_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H20_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([20, 64]) from checkpoint, the shape in current model is torch.Size([20, 128]).
[47/60] Processing: exp_single_ema_a095_Test-m2_S008_seed42 -> exp_single_ema_a095_Test-m2_S008_seed42
Saved compare_result/exp_single_ema_a095_Test-m2_S008_seed42/exp_single_ema_a095_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0631, R²=0.9701, Lag=6.5ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a095_Test-m2_S008_seed42/exp_single_ema_a095_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a095_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a095_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[48/60] Processing: exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42 -> exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42/exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (377555,)
[EVAL] Results: MAE=0.0468, RMSE=0.0790, R²=0.9531, Lag=25.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42/exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[49/60] Processing: exp_single_ema_a090_Test-m1_S011_seed42 -> exp_single_ema_a090_Test-m1_S011_seed42
Saved compare_result/exp_single_ema_a090_Test-m1_S011_seed42/exp_single_ema_a090_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0291, R²=0.9914, Lag=-1573.3ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a090_Test-m1_S011_seed42/exp_single_ema_a090_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a090_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a090_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[50/60] Processing: exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42 -> exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42/exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42/exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[51/60] Processing: exp_single_ema_a090_Test-m2_S008_seed42 -> exp_single_ema_a090_Test-m2_S008_seed42
Saved compare_result/exp_single_ema_a090_Test-m2_S008_seed42/exp_single_ema_a090_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0631, R²=0.9701, Lag=6.5ms
  [SAVED] Trajectory plot: compare_result/exp_single_ema_a090_Test-m2_S008_seed42/exp_single_ema_a090_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_single_ema_a090_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_single_ema_a090_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[52/60] Processing: exp_multistep_H10_Test-m1_S004_seed42 -> exp_multistep_H10_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_Test-m1_S004_seed42/exp_multistep_H10_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_Test-m1_S004_seed42/exp_multistep_H10_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[53/60] Processing: exp_ar_feedback_sched_Test-m2_S008_seed42 -> exp_ar_feedback_sched_Test-m2_S008_seed42
Saved compare_result/exp_ar_feedback_sched_Test-m2_S008_seed42/exp_ar_feedback_sched_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m2_S008_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0261, RMSE=0.0458, R²=0.9842, Lag=4.0ms
  [SAVED] Trajectory plot: compare_result/exp_ar_feedback_sched_Test-m2_S008_seed42/exp_ar_feedback_sched_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_ar_feedback_sched_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_ar_feedback_sched_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 31, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[54/60] Processing: exp_multistep_H10_ema_a090_Test-m2_S008_seed42 -> exp_multistep_H10_ema_a090_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_ema_a090_Test-m2_S008_seed42/exp_multistep_H10_ema_a090_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0802, R²=0.9517, Lag=33.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_ema_a090_Test-m2_S008_seed42/exp_multistep_H10_ema_a090_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_ema_a090_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_ema_a090_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[55/60] Processing: exp_multistep_H10_overlap_mean_Test-m1_S004_seed42 -> exp_multistep_H10_overlap_mean_Test-m1_S004_seed42
Saved compare_result/exp_multistep_H10_overlap_mean_Test-m1_S004_seed42/exp_multistep_H10_overlap_mean_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (70404,)
[EVAL] Results: MAE=0.0221, RMSE=0.0370, R²=0.9862, Lag=570.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_overlap_mean_Test-m1_S004_seed42/exp_multistep_H10_overlap_mean_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_overlap_mean_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_overlap_mean_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[56/60] Processing: exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42 -> exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42/exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42/exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[57/60] Processing: exp_tcn_gru_head_h64_Test-m1_S004_seed42 -> exp_tcn_gru_head_h64_Test-m1_S004_seed42
Saved compare_result/exp_tcn_gru_head_h64_Test-m1_S004_seed42/exp_tcn_gru_head_h64_Test-m1_S004_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0155, RMSE=0.0283, R²=0.9919, Lag=7448.3ms
  [SAVED] Trajectory plot: compare_result/exp_tcn_gru_head_h64_Test-m1_S004_seed42/exp_tcn_gru_head_h64_Test-m1_S004_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_tcn_gru_head_h64_Test-m1_S004_seed42...
  [ERROR] Failed to generate plots for exp_tcn_gru_head_h64_Test-m1_S004_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[58/60] Processing: exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42 -> exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42
Saved compare_result/exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42/exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
  [SAVED] Trajectory plot: compare_result/exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42/exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 30, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 30, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 128]).
[59/60] Processing: exp_ar_feedback_k1_Test-m1_S011_seed42 -> exp_ar_feedback_k1_Test-m1_S011_seed42
Saved compare_result/exp_ar_feedback_k1_Test-m1_S011_seed42/exp_ar_feedback_k1_Test-m1_S011_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m1_S011_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0178, RMSE=0.0304, R²=0.9906, Lag=-12466.7ms
  [SAVED] Trajectory plot: compare_result/exp_ar_feedback_k1_Test-m1_S011_seed42/exp_ar_feedback_k1_Test-m1_S011_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_ar_feedback_k1_Test-m1_S011_seed42...
  [ERROR] Failed to generate plots for exp_ar_feedback_k1_Test-m1_S011_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 31, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
[60/60] Processing: exp_ar_feedback_k1_Test-m2_S008_seed42 -> exp_ar_feedback_k1_Test-m2_S008_seed42
Saved compare_result/exp_ar_feedback_k1_Test-m2_S008_seed42/exp_ar_feedback_k1_Test-m2_S008_seed42/training_curves.png
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m2_S008_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0261, RMSE=0.0458, R²=0.9842, Lag=4.0ms
  [SAVED] Trajectory plot: compare_result/exp_ar_feedback_k1_Test-m2_S008_seed42/exp_ar_feedback_k1_Test-m2_S008_seed42/trajectory.png
[INFO] Generating Detailed Grid Plots for exp_ar_feedback_k1_Test-m2_S008_seed42...
  [ERROR] Failed to generate plots for exp_ar_feedback_k1_Test-m2_S008_seed42: Error(s) in loading state_dict for TCN_MLP:
	size mismatch for input_norm.weight: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for input_norm.bias: copying a param with shape torch.Size([31]) from checkpoint, the shape in current model is torch.Size([0]).
	size mismatch for enc.network.0.conv1.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.0.weight: copying a param with shape torch.Size([32, 31, 5]) from checkpoint, the shape in current model is torch.Size([64, 0, 3]).
	size mismatch for enc.network.0.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.0.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.0.downsample.weight: copying a param with shape torch.Size([32, 31, 1]) from checkpoint, the shape in current model is torch.Size([64, 0, 1]).
	size mismatch for enc.network.0.downsample.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv1.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.conv2.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.conv2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.0.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.1.net.5.weight: copying a param with shape torch.Size([32, 32, 5]) from checkpoint, the shape in current model is torch.Size([64, 64, 3]).
	size mismatch for enc.network.1.net.5.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for enc.network.2.conv1.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.conv1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.conv2.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.conv2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.0.weight: copying a param with shape torch.Size([64, 32, 5]) from checkpoint, the shape in current model is torch.Size([128, 64, 3]).
	size mismatch for enc.network.2.net.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.net.5.weight: copying a param with shape torch.Size([64, 64, 5]) from checkpoint, the shape in current model is torch.Size([128, 128, 3]).
	size mismatch for enc.network.2.net.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for enc.network.2.downsample.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).
	size mismatch for enc.network.2.downsample.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_base.0.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([128, 128]).
	size mismatch for head_base.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for head_out.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([1, 128]).
Starting Ablation Analysis Report...
Found 60 potential experiment folders.
[1/60] Evaluating Exp_IMU_Orientation_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m1_S004_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m1_S004_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0332, RMSE=0.0497, R²=0.9750, Lag=12610.0ms
[2/60] Evaluating Exp_IMU_Orientation_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m1_S011_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m1_S011_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0227, RMSE=0.0370, R²=0.9861, Lag=9406.7ms
[3/60] Evaluating Exp_IMU_Orientation_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] Exp_IMU_Orientation_Test-m2_S008_seed42
[EVAL] Config: configs/Exp_IMU_Orientation.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/Exp_IMU_Orientation_Test-m2_S008_seed42/scaler.npz (mean shape=(28,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=28, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0268, RMSE=0.0441, R²=0.9854, Lag=0.5ms
[4/60] Evaluating baseline_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m1_S004_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/baseline_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0575, R²=0.9667, Lag=-11663.3ms
[5/60] Evaluating baseline_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m1_S011_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/baseline_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0292, R²=0.9914, Lag=-1571.7ms
[6/60] Evaluating baseline_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] baseline_Test-m2_S008_seed42
[EVAL] Config: configs/baseline.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/baseline_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0632, R²=0.9700, Lag=6.5ms
[7/60] Evaluating exp_ar_feedback_k1_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m1_S004_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0445, RMSE=0.0668, R²=0.9550, Lag=448.3ms
[8/60] Evaluating exp_ar_feedback_k1_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m1_S011_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0178, RMSE=0.0304, R²=0.9906, Lag=-12466.7ms
[9/60] Evaluating exp_ar_feedback_k1_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_k1_Test-m2_S008_seed42
[EVAL] Config: configs/exp_ar_feedback_k1.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_k1_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0261, RMSE=0.0458, R²=0.9842, Lag=4.0ms
[10/60] Evaluating exp_ar_feedback_sched_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m1_S004_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0445, RMSE=0.0668, R²=0.9550, Lag=448.3ms
[11/60] Evaluating exp_ar_feedback_sched_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m1_S011_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0178, RMSE=0.0304, R²=0.9906, Lag=-12466.7ms
[12/60] Evaluating exp_ar_feedback_sched_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_ar_feedback_sched_Test-m2_S008_seed42
[EVAL] Config: configs/exp_ar_feedback_sched.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_ar_feedback_sched_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] AR Feedback detected. Augmenting input_dim 30 -> 31
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=31, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0261, RMSE=0.0458, R²=0.9842, Lag=4.0ms
[13/60] Evaluating exp_multistep_H05_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (70380, 5, 1)
[EVAL] Results: MAE=0.0962, RMSE=0.1381, R²=0.8077, Lag=-7043.3ms
[14/60] Evaluating exp_multistep_H05_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (70177, 5, 1)
[EVAL] Results: MAE=0.0150, RMSE=0.0294, R²=0.9913, Lag=4815.0ms
[15/60] Evaluating exp_multistep_H05_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H05_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H05.yaml
[EVAL] Data: win_in=300, win_out=5, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H05_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=5
[EVAL] Final y_pred shape: (377475, 5, 1)
[EVAL] Results: MAE=0.0353, RMSE=0.0622, R²=0.9709, Lag=24.0ms
[16/60] Evaluating exp_multistep_H10_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[17/60] Evaluating exp_multistep_H10_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[18/60] Evaluating exp_multistep_H10_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[19/60] Evaluating exp_multistep_H10_ema_a090_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0375, R²=0.9858, Lag=610.0ms
[20/60] Evaluating exp_multistep_H10_ema_a090_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0274, R²=0.9924, Lag=763.3ms
[21/60] Evaluating exp_multistep_H10_ema_a090_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_ema_a090_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_ema_a090_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0802, R²=0.9517, Lag=33.0ms
[22/60] Evaluating exp_multistep_H10_overlap_mean_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (70404,)
[EVAL] Results: MAE=0.0221, RMSE=0.0370, R²=0.9862, Lag=570.0ms
[23/60] Evaluating exp_multistep_H10_overlap_mean_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (70201,)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9923, Lag=721.7ms
[24/60] Evaluating exp_multistep_H10_overlap_mean_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_mean_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_mean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_mean_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=mean, H=10)...
[EVAL] Final y_pred shape: (377555,)
[EVAL] Results: MAE=0.0465, RMSE=0.0786, R²=0.9536, Lag=20.0ms
[25/60] Evaluating exp_multistep_H10_overlap_median_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (70404, 1)
[EVAL] Results: MAE=0.0219, RMSE=0.0370, R²=0.9862, Lag=578.3ms
[26/60] Evaluating exp_multistep_H10_overlap_median_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (70201, 1)
[EVAL] Results: MAE=0.0124, RMSE=0.0276, R²=0.9923, Lag=720.0ms
[27/60] Evaluating exp_multistep_H10_overlap_median_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_median_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_median.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_median_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=median, H=10)...
[EVAL] Final y_pred shape: (377555, 1)
[EVAL] Results: MAE=0.0464, RMSE=0.0789, R²=0.9533, Lag=20.0ms
[28/60] Evaluating exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (70404,)
[EVAL] Results: MAE=0.0220, RMSE=0.0371, R²=0.9861, Lag=588.3ms
[29/60] Evaluating exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (70201,)
[EVAL] Results: MAE=0.0124, RMSE=0.0274, R²=0.9924, Lag=738.3ms
[30/60] Evaluating exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_overlap_wmean.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_overlap_wmean_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Applying Overlap Ensemble (method=weighted_mean, H=10)...
[EVAL] Final y_pred shape: (377555,)
[EVAL] Results: MAE=0.0468, RMSE=0.0790, R²=0.9531, Lag=25.0ms
[31/60] Evaluating exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[32/60] Evaluating exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[33/60] Evaluating exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam001.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam001_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[34/60] Evaluating exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[35/60] Evaluating exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[36/60] Evaluating exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam01.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam01_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[37/60] Evaluating exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70350, 10, 1)
[EVAL] Results: MAE=0.0222, RMSE=0.0376, R²=0.9857, Lag=611.7ms
[38/60] Evaluating exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (70147, 10, 1)
[EVAL] Results: MAE=0.0125, RMSE=0.0275, R²=0.9924, Lag=765.0ms
[39/60] Evaluating exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H10_smooth_lam05.yaml
[EVAL] Data: win_in=300, win_out=10, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H10_smooth_lam05_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=10
[EVAL] Final y_pred shape: (377375, 10, 1)
[EVAL] Results: MAE=0.0474, RMSE=0.0803, R²=0.9516, Lag=33.0ms
[40/60] Evaluating exp_multistep_H20_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m1_S004_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (70290, 20, 1)
[EVAL] Results: MAE=0.0490, RMSE=0.0771, R²=0.9401, Lag=-6661.7ms
[41/60] Evaluating exp_multistep_H20_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m1_S011_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (70087, 20, 1)
[EVAL] Results: MAE=0.0209, RMSE=0.0408, R²=0.9832, Lag=-2330.0ms
[42/60] Evaluating exp_multistep_H20_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_multistep_H20_Test-m2_S008_seed42
[EVAL] Config: configs/exp_multistep_H20.yaml
[EVAL] Data: win_in=300, win_out=20, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_multistep_H20_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=20
[EVAL] Final y_pred shape: (377175, 20, 1)
[EVAL] Results: MAE=0.0524, RMSE=0.0787, R²=0.9534, Lag=41.0ms
[43/60] Evaluating exp_single_ema_a080_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0573, R²=0.9669, Lag=-11668.3ms
[44/60] Evaluating exp_single_ema_a080_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0145, RMSE=0.0291, R²=0.9914, Lag=-1575.0ms
[45/60] Evaluating exp_single_ema_a080_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a080_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a080.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a080_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.8)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0630, R²=0.9702, Lag=6.5ms
[46/60] Evaluating exp_single_ema_a090_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0574, R²=0.9668, Lag=-11665.0ms
[47/60] Evaluating exp_single_ema_a090_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0291, R²=0.9914, Lag=-1573.3ms
[48/60] Evaluating exp_single_ema_a090_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a090_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a090.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a090_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.9)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0631, R²=0.9701, Lag=6.5ms
[49/60] Evaluating exp_single_ema_a095_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m1_S004_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0370, RMSE=0.0574, R²=0.9668, Lag=-11665.0ms
[50/60] Evaluating exp_single_ema_a095_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m1_S011_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0146, RMSE=0.0291, R²=0.9914, Lag=-1573.3ms
[51/60] Evaluating exp_single_ema_a095_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_single_ema_a095_Test-m2_S008_seed42
[EVAL] Config: configs/exp_single_ema_a095.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_single_ema_a095_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Applying EMA Post-Filter (alpha=0.95)...
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0387, RMSE=0.0631, R²=0.9701, Lag=6.5ms
[52/60] Evaluating exp_tcn_gru_head_h32_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0281, RMSE=0.0414, R²=0.9827, Lag=268.3ms
[53/60] Evaluating exp_tcn_gru_head_h32_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0175, RMSE=0.0424, R²=0.9818, Lag=8981.7ms
[54/60] Evaluating exp_tcn_gru_head_h32_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0329, RMSE=0.0675, R²=0.9658, Lag=2.5ms
[55/60] Evaluating exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0281, RMSE=0.0414, R²=0.9827, Lag=268.3ms
[56/60] Evaluating exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0175, RMSE=0.0424, R²=0.9818, Lag=8981.7ms
[57/60] Evaluating exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h32_smooth.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h32_smooth_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0329, RMSE=0.0675, R²=0.9658, Lag=2.5ms
[58/60] Evaluating exp_tcn_gru_head_h64_Test-m1_S004_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m1_S004_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S004...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m1_S004_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70380, 1)
[EVAL] Results: MAE=0.0155, RMSE=0.0283, R²=0.9919, Lag=7448.3ms
[59/60] Evaluating exp_tcn_gru_head_h64_Test-m1_S011_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m1_S011_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m1_S011...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm1_': ./combined_data_milestone1.h5 | Subs: 1
     Loaded 6 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m1_S011_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (70177, 1)
[EVAL] Results: MAE=0.0242, RMSE=0.0537, R²=0.9707, Lag=-468.3ms
[60/60] Evaluating exp_tcn_gru_head_h64_Test-m2_S008_seed42...
[EVAL] Loaded base defaults from configs/baseline.yaml

============================================================
[EVAL] exp_tcn_gru_head_h64_Test-m2_S008_seed42
[EVAL] Config: configs/exp_tcn_gru_head_h64.yaml
[EVAL] Data: win_in=300, win_out=1, stride_train=5, stride_eval=1
[EVAL] est_tick_ranges=[5], lpf_cutoff=0.5, lpf_order=4
[EVAL] Loading Test Data for Subject m2_S008...
[DATA] Loading Multi-Source: keys=['m1_', 'm2_']
  -> Source 'm2_': ./combined_data.h5 | Subs: 1
     Loaded 20 trials
[EVAL] Applying scaler from experiments/exp_tcn_gru_head_h64_Test-m2_S008_seed42/scaler.npz (mean shape=(30,))
[EVAL] Model: type=TCN_GRU, ch=[32, 32, 64, 64, 128, 128], k=5
[EVAL] Dropout=0.2, head_dropout=0.5, hidden=[64]
[EVAL] use_input_norm=True, norm_type=layer
[EVAL] input_dim=30, output_dim=1, horizon=1
[EVAL] Final y_pred shape: (377475, 1)
[EVAL] Results: MAE=0.0778, RMSE=0.1195, R²=0.8927, Lag=9.0ms

Baseline (baseline) found: MAE=0.0301

====================================================================================================
Experiment Group                         | MAE      | Delta    | % Chg    | Lag(ms) 
----------------------------------------------------------------------------------------------------
exp_tcn_gru_head_h32_smooth              | 0.0262   | -0.0039   | -13.0%    | 3084.2
exp_tcn_gru_head_h32                     | 0.0262   | -0.0039   | -13.0%    | 3084.2
exp_multistep_H10_overlap_median         | 0.0269   | -0.0032   | -10.6%    | 439.4
exp_multistep_H10_overlap_mean           | 0.0270   | -0.0031   | -10.3%    | 437.2
exp_multistep_H10_overlap_wmean          | 0.0271   | -0.0030   | -10.1%    | 450.6
exp_multistep_H10_ema_a090               | 0.0273   | -0.0028   | -9.2%    | 468.8
exp_multistep_H10_smooth_lam01           | 0.0274   | -0.0027   | -9.1%    | 469.9
exp_multistep_H10_smooth_lam001          | 0.0274   | -0.0027   | -9.1%    | 469.9
exp_multistep_H10                        | 0.0274   | -0.0027   | -9.1%    | 469.9
exp_multistep_H10_smooth_lam05           | 0.0274   | -0.0027   | -9.1%    | 469.9
Exp_IMU_Orientation                      | 0.0276   | -0.0025   | -8.5%    | 7339.1
exp_ar_feedback_k1                       | 0.0295   | -0.0006   | -2.2%    | -4004.8
exp_ar_feedback_sched                    | 0.0295   | -0.0006   | -2.2%    | -4004.8
exp_single_ema_a080                      | 0.0301   | -0.0001   | -0.2%    | -4412.3
exp_single_ema_a090                      | 0.0301   | -0.0000   | -0.1%    | -4410.6
exp_single_ema_a095                      | 0.0301   | -0.0000   | -0.0%    | -4410.6
baseline                                 | 0.0301   | +0.0000   | +0.0%    | -4409.5
exp_tcn_gru_head_h64                     | 0.0392   | +0.0091   | +30.1%    | 2329.7
exp_multistep_H20                        | 0.0408   | +0.0107   | +35.4%    | -2983.6
exp_multistep_H05                        | 0.0488   | +0.0187   | +62.2%    | -734.8
====================================================================================================

Saved Summary CSV to: compare_result/final_ablation_summary.csv
Saved plots to compare_result/
